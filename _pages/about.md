---
permalink: /
title: "About Me"
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# About Me
Hello, hope you are doing great! I'm first year PhD student at the department of [Computer Science and Software Engineering](https://eng.auburn.edu/csse/#gsc.tab=0) at [Auburn University](https://www.auburn.edu/), under the supervision of [Dr. Sathyanarayanan N. Aakur](https://saakur.github.io/).

I obtained my Masterâ€™s degree in Computer Science and Software Engineering from Auburn University, USA, in 2024,  
and my Bachelorâ€™s degree in Computer Science and Technology from Central South University, China, in 2021.

Currently, I'm working in the group of [Open-ended Reasoning and Knowledge Acquisition (ORCA) Lab](https://saakur.github.io/group.html) led by Dr. Aakur. My research focuses on Active Event Perception, Visual Affordance Grounding and Multimodal Open World Understanding in the context of computer vision for robotic applications.

# News
- *2025.06*: &nbsp;ðŸŽ‰ðŸŽ‰ Congratulations to labmate Sanjoy Kundu for receiving the Outstanding Reviewer Award at CVPR 2025
- *2025.06*: &nbsp;ðŸŽ‰ðŸŽ‰ I presented a paper at the Vision-based Assistants in the Real-World Workshop, CVPR 2025. 

# Publications 

<!-- === Paper 1 === -->
<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">RA-L 2025</div>
      <img src='images/ease.png' alt="ease-paper" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">

**[EASE: Embodied Active Event Perception via Self-Supervised Free Energy Minimization](#)**  
**Zhou Chen**, Sanjoy Kundu, Harsimran Baweja, Sathyanarayanan Aakur  
*IEEE Robotics and Automation Letters (RA-L)*, 2025. _(Impact Factor: 4.6)_  
[**Project Link**](https://saakur.github.io/Projects/EASE/index.html)
</div>
</div>

# Workshop
- **Learning to Perceive and Act: Active Event Understanding via Predictive Free Energy Minimization**  
  *Zhou Chen, Sanjoy Kundu, Harsimran Bhaweja, Sathyanarayanan N. Aakur*  
  Vision-based Assistants in the Real-World Workshop, CVPR 2025

- **A Self-supervised Framework for Embodied Active Event Perception**  
  *Zhou Chen, Sanjoy Kundu, Harsimran Bhaweja, Sathyanarayanan N. Aakur*  
  How do Robots Care? Workshop, IEEE International Conference on Robotics and Automation (ICRA), 2025

- **A Self-supervised Framework for Embodied Active Event Perception**  
  *Zhou Chen, Sanjoy Kundu, Harsimran Bhaweja, Sathyanarayanan N. Aakur*  
  ICRA 2025 Late Breaking Works


# Work
- **Hualu Zhida Technology Co., Ltd.**, Dalian, China  
  *Junior Software Engineer, Embedded Department â€“ Android Development Group*  
  *Aug 2021 â€“ Jun 2022*

# Internships
- *2020.09.07 - 2021.01.03*, ZTE Corporation, China.


# Collaborate
I am fortunate to collaborate with the following researchers:

<p align="center">
  <a href="https://scholar.google.com/citations?user=XXX" target="_blank">
    <img src="/assets/imgs/alice.jpg" width="100"><br>
    <sub><b>Alice Zhang</b></sub>
  </a>
  &nbsp;&nbsp;&nbsp;&nbsp;
  <a href="https://github.com/bobliu" target="_blank">
    <img src="/assets/imgs/bob.jpg" width="100"><br>
    <sub><b>Bob Liu</b></sub>
  </a>
  &nbsp;&nbsp;&nbsp;&nbsp;
  <a href="https://zhouchenlab.com" target="_blank">
    <img src="/assets/imgs/zhouchen.jpg" width="100"><br>
    <sub><b>Zhou Chen</b></sub>
  </a>
</p>
